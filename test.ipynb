{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cdb9cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir='./munshi-ai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "608986de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/p0s0cad/work/personal-projects/ai-munshi/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model sucessfully loaded \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "# === Load the fine-tuned model ===\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,  # path to your fine-tuned model\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=\"/tmp/phi4_cache\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "print('model sucessfully loaded ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aa363ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Prompt:\n",
      "<|system|>\n",
      "You are an expert Python assistant. Generate valid Pandas code based on the user's query.\n",
      "The DataFrame contains the following columns: CustomerID, PurchaseAmount, Region\n",
      "<|end|>\n",
      "<|user|>\n",
      "What is the average purchase amount per region?\n",
      "<|end|>\n",
      "<|assistant|>\n",
      "\n",
      "‚úÖ Extracted df_code: df.groupby('region')['Purchase_amount'].agg('mean')\n",
      "\n",
      "üß™ Prompt:\n",
      "<|system|>\n",
      "You are an expert Python assistant. Generate valid Pandas code based on the user's query.\n",
      "The DataFrame contains the following columns: Date, Product, Sales, Category\n",
      "<|end|>\n",
      "<|user|>\n",
      "Filter rows where sales are above 1000 and category is 'Electronics'\n",
      "<|end|>\n",
      "<|assistant|>\n",
      "\n",
      "‚úÖ Extracted df_code: df[df['sales'] > 1000]\n",
      "\n",
      "üß™ Prompt:\n",
      "<|system|>\n",
      "You are an expert Python assistant. Generate valid Pandas code based on the user's query.\n",
      "The DataFrame contains the following columns: OrderID, CustomerName, OrderDate\n",
      "<|end|>\n",
      "<|user|>\n",
      "Sort the data by order date in descending order\n",
      "<|end|>\n",
      "<|assistant|>\n",
      "\n",
      "‚úÖ Extracted df_code: df.sort_values(by='order_date', ascending=False)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "# === Generate predictions ===\n",
    "for test in test_cases:\n",
    "    col_str = \", \".join(test[\"columns\"])\n",
    "    prompt = (\n",
    "        f\"<|system|>\\nYou are an expert Python assistant. Generate valid Pandas code based on the user's query.\\n\"\n",
    "        f\"The DataFrame contains the following columns: {col_str}\\n<|end|>\\n\"\n",
    "        f\"<|user|>\\n{test['query']}\\n<|end|>\\n\"\n",
    "        \"<|assistant|>\\n\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nüß™ Prompt:\")\n",
    "    print(prompt)\n",
    "    \n",
    "    output = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=150,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        top_k=50\n",
    "    )\n",
    "\n",
    "    full_text = output[0][\"generated_text\"]\n",
    "    # print(\"\\nüì§ Raw Output:\")\n",
    "    # print(full_text)\n",
    "\n",
    "    # === Extract JSON object from text\n",
    "    json_match = re.search(r\"\\{.*?\\}\", full_text, re.DOTALL)\n",
    "    if json_match:\n",
    "        try:\n",
    "            raw_json = json_match.group(0).replace(\"<|end|>\", \"\")\n",
    "            result = json.loads(raw_json)\n",
    "            df_code = result.get(\"df_code\", None)\n",
    "            print(\"‚úÖ Extracted df_code:\", df_code)\n",
    "        except Exception as e:\n",
    "            print(\"‚ùå JSON parse error:\", e)\n",
    "    else:\n",
    "        print(\"‚ùå No JSON block found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
